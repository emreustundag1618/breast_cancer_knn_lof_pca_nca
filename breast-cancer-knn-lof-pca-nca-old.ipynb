{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Outline:\n\n* [Introduction](#1)\n* [Packages & Libraries](#3)\n* [Basic EDA and Visualization](#4)\n* [Data Preprocessing & Outlier Analysis, LOF](#5)\n* [Model](#6)\n    * [K-Nearest Neighbors (KNN) Algorithm](#7)\n    * [KNN Best Parameters](#8)\n* [Dimensionality Reduction](#9)\n    * [Principal Component Analysis (PCA)](#10)\n    * [Neighborhood Component Analysis (NCA)](#11)\n* [Results & Evaluation](#12)","metadata":{}},{"cell_type":"markdown","source":"<a id = \"1\"></a>\n### Introduction\n<img src=\"https://www.jbcp.jo/sites/default/files/2018-05/Breast-Cancer-Staging.jpg\">","metadata":{"execution":{"iopub.status.busy":"2022-11-01T09:00:43.963338Z","iopub.execute_input":"2022-11-01T09:00:43.963763Z","iopub.status.idle":"2022-11-01T09:00:43.970732Z","shell.execute_reply.started":"2022-11-01T09:00:43.963731Z","shell.execute_reply":"2022-11-01T09:00:43.969396Z"}}},{"cell_type":"markdown","source":"**Background:** Breast cancer is a type of cancer that starts in the breast. It can start in one or both breasts. Breast cancer can spread when the cancer cells get into the blood or lymph system and then are carried to other parts of the body. The lymph (or lymphatic) system is a part of your body's immune system. It is a network of lymph nodes (small, bean-sized glands), ducts or vessels, and organs that work together to collect and carry clear lymph fluid through the body tissues to the blood. The clear lymph fluid inside the lymph vessels contains tissue by-products and waste material, as well as immune system cells.\n\nSource: [https://www.cancer.org/cancer/breast-cancer/about/what-is-breast-cancer.html]\n\n**Motivation:** Finding breast cancer early and getting state-of-the-art cancer treatment are two of the most important strategies for preventing deaths from breast cancer. Breast cancer that’s found early, when it’s small and has not spread, is easier to treat successfully. In this work we will apply a breast cancer classification with KNN algorithm. We will also analyze the outliers of the dataset before KNN training. To increase model accuracy dimension reduction techniques like PCA and NCA will be performed.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"2\"></a>\n### Packages & Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor\nfrom sklearn.decomposition import PCA\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-03T13:12:05.845392Z","iopub.execute_input":"2022-11-03T13:12:05.845869Z","iopub.status.idle":"2022-11-03T13:12:05.853805Z","shell.execute_reply.started":"2022-11-03T13:12:05.845831Z","shell.execute_reply":"2022-11-03T13:12:05.852501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**First look on data**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\")\ndata.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:06.879854Z","iopub.execute_input":"2022-11-03T13:12:06.880308Z","iopub.status.idle":"2022-11-03T13:12:06.923746Z","shell.execute_reply.started":"2022-11-03T13:12:06.880271Z","shell.execute_reply":"2022-11-03T13:12:06.922506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(['id','Unnamed: 32'], axis = 1)\ndata.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:07.369840Z","iopub.execute_input":"2022-11-03T13:12:07.370306Z","iopub.status.idle":"2022-11-03T13:12:07.402079Z","shell.execute_reply.started":"2022-11-03T13:12:07.370263Z","shell.execute_reply":"2022-11-03T13:12:07.400785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.rename(columns = {'diagnosis':'target'}, inplace = True)\ndata.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:08.591195Z","iopub.execute_input":"2022-11-03T13:12:08.591667Z","iopub.status.idle":"2022-11-03T13:12:08.621581Z","shell.execute_reply.started":"2022-11-03T13:12:08.591633Z","shell.execute_reply":"2022-11-03T13:12:08.620043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data['target'])","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:09.178751Z","iopub.execute_input":"2022-11-03T13:12:09.179251Z","iopub.status.idle":"2022-11-03T13:12:09.380542Z","shell.execute_reply.started":"2022-11-03T13:12:09.179185Z","shell.execute_reply":"2022-11-03T13:12:09.379120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.target.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:09.743123Z","iopub.execute_input":"2022-11-03T13:12:09.743610Z","iopub.status.idle":"2022-11-03T13:12:09.752271Z","shell.execute_reply.started":"2022-11-03T13:12:09.743574Z","shell.execute_reply":"2022-11-03T13:12:09.750642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['target'] = [1 if i.strip() == 'M' else 0 for i in data['target']]","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:10.853613Z","iopub.execute_input":"2022-11-03T13:12:10.854031Z","iopub.status.idle":"2022-11-03T13:12:10.861874Z","shell.execute_reply.started":"2022-11-03T13:12:10.853996Z","shell.execute_reply":"2022-11-03T13:12:10.860333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:12.659767Z","iopub.execute_input":"2022-11-03T13:12:12.660138Z","iopub.status.idle":"2022-11-03T13:12:12.690597Z","shell.execute_reply.started":"2022-11-03T13:12:12.660109Z","shell.execute_reply":"2022-11-03T13:12:12.689510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:13.656444Z","iopub.execute_input":"2022-11-03T13:12:13.656888Z","iopub.status.idle":"2022-11-03T13:12:13.665099Z","shell.execute_reply.started":"2022-11-03T13:12:13.656854Z","shell.execute_reply":"2022-11-03T13:12:13.663785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:14.296098Z","iopub.execute_input":"2022-11-03T13:12:14.296523Z","iopub.status.idle":"2022-11-03T13:12:14.312104Z","shell.execute_reply.started":"2022-11-03T13:12:14.296492Z","shell.execute_reply":"2022-11-03T13:12:14.310754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no missing value in dataset","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:17.327334Z","iopub.execute_input":"2022-11-03T13:12:17.327705Z","iopub.status.idle":"2022-11-03T13:12:17.421720Z","shell.execute_reply.started":"2022-11-03T13:12:17.327677Z","shell.execute_reply":"2022-11-03T13:12:17.420379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: To get data features into the same space, we have to scale all features","metadata":{}},{"cell_type":"markdown","source":"<a id = \"3\"></a>\n### Basic EDA & Visualization","metadata":{}},{"cell_type":"code","source":"# Correlations\ncorr_matrix = data.corr()\ncorr_matrix","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:19.665679Z","iopub.execute_input":"2022-11-03T13:12:19.666087Z","iopub.status.idle":"2022-11-03T13:12:19.716406Z","shell.execute_reply.started":"2022-11-03T13:12:19.666054Z","shell.execute_reply":"2022-11-03T13:12:19.715097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clustermap with Pearson Correlation Coefficients\nsns.clustermap(corr_matrix, annot = True, fmt = \".2f\", figsize = (18, 15))\nplt.title(\"Correlation Between Features\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:21.978106Z","iopub.execute_input":"2022-11-03T13:12:21.978588Z","iopub.status.idle":"2022-11-03T13:12:26.755319Z","shell.execute_reply.started":"2022-11-03T13:12:21.978553Z","shell.execute_reply":"2022-11-03T13:12:26.754326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# threshold to explore highly correlated features\nthreshold = 0.75\nfilter_ = np.abs(corr_matrix['target']) > threshold\ncorr_features = corr_matrix.columns[filter_].tolist()\ncorr_features","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:26.757117Z","iopub.execute_input":"2022-11-03T13:12:26.757503Z","iopub.status.idle":"2022-11-03T13:12:26.766942Z","shell.execute_reply.started":"2022-11-03T13:12:26.757471Z","shell.execute_reply":"2022-11-03T13:12:26.765756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize which features are highly correlated\nsns.heatmap(data[corr_features].corr(), annot = True, fmt = \".2f\")\nplt.title(\"Correlation Between Features\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:31.115541Z","iopub.execute_input":"2022-11-03T13:12:31.115930Z","iopub.status.idle":"2022-11-03T13:12:31.482061Z","shell.execute_reply.started":"2022-11-03T13:12:31.115899Z","shell.execute_reply":"2022-11-03T13:12:31.480774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some correlated features","metadata":{}},{"cell_type":"code","source":"# melting data for box plot\ndata_melted = pd.melt(data, id_vars = 'target', var_name = 'feature', value_name = 'value')\ndata_melted","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:33.509614Z","iopub.execute_input":"2022-11-03T13:12:33.510031Z","iopub.status.idle":"2022-11-03T13:12:33.530997Z","shell.execute_reply.started":"2022-11-03T13:12:33.509997Z","shell.execute_reply":"2022-11-03T13:12:33.530030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Box plot to detect outliers\nplt.figure(figsize = (10, 8))\nsns.boxplot(x = 'feature', y = 'value', hue = 'target', data = data_melted)\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:37.018675Z","iopub.execute_input":"2022-11-03T13:12:37.019087Z","iopub.status.idle":"2022-11-03T13:12:38.226367Z","shell.execute_reply.started":"2022-11-03T13:12:37.019054Z","shell.execute_reply":"2022-11-03T13:12:38.225418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As seen, box plots is a little bit confusing because non-scaled features. We have to normalize the features to solve this issue.","metadata":{}},{"cell_type":"code","source":"# decreasing threshold to see if the distributions have skewness\nthreshold = 0.75\nfilter_ = np.abs(corr_matrix['target']) > threshold\ncorr_features = corr_matrix.columns[filter_].tolist()\nsns.pairplot(data[corr_features], diag_kind = 'kde', markers = \"+\", hue = 'target')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:40.214108Z","iopub.execute_input":"2022-11-03T13:12:40.214727Z","iopub.status.idle":"2022-11-03T13:12:44.544496Z","shell.execute_reply.started":"2022-11-03T13:12:40.214675Z","shell.execute_reply":"2022-11-03T13:12:44.543158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src=\"https://studiousguy.com/wp-content/uploads/2021/08/Skewed-Distribution.jpg\" width=\"500\" height=\"600\">","metadata":{}},{"cell_type":"markdown","source":"Skewness is a measurement of the distortion of symmetrical distribution or asymmetry in a data set. Skewness is demonstrated on a bell curve when data points are not distributed symmetrically to the left and right sides of the median on a bell curve. \n\n* A skewness value of 0 in the output denotes a symmetrical distribution of values in row 1.\n* A negative skewness value in the output indicates an asymmetry in the distribution corresponding to row 2 and the tail is larger towards the left hand side of the distribution.\n* A positive skewness value in the output indicates an asymmetry in the distribution corresponding to row 3 and the tail is larger towards the right hand side of the distribution.\n\nSo which features have skewness?","metadata":{}},{"cell_type":"code","source":"skewness = pd.DataFrame(data.skew(), columns = ['skewness'])\nskewness","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-11-03T13:12:47.552563Z","iopub.execute_input":"2022-11-03T13:12:47.552962Z","iopub.status.idle":"2022-11-03T13:12:47.570096Z","shell.execute_reply.started":"2022-11-03T13:12:47.552932Z","shell.execute_reply":"2022-11-03T13:12:47.568964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skewness['skewness'] = [\"Positively skewed\" if i >= 1 else \"Negatively skewed\" if i <= -1 else \"Normal Distribution\" for i in skewness['skewness']]\nskewness","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:12:49.935962Z","iopub.execute_input":"2022-11-03T13:12:49.936383Z","iopub.status.idle":"2022-11-03T13:12:49.949954Z","shell.execute_reply.started":"2022-11-03T13:12:49.936351Z","shell.execute_reply":"2022-11-03T13:12:49.948410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are many skewed features on data. We must solve this issue too.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"4\"></a>\n### Data Preprocessing & Outlier Analysis","metadata":{}},{"cell_type":"markdown","source":"**Density based Outlier Detection: Local Outlier Factor (LOF)** : Compare local density of one point to local density of its K-NN\n* LOF > 1 ==> outlier / anomaly\n* LOF < 1 ==> inlier","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/1400/1*5tBfkFHgFcqyNuDa6eNkNQ.jpeg\" width=\"500\" height=\"600\" alt = \"Source:https://medium.com/mlpoint/local-outlier-factor-a-way-to-detect-outliers-dde335d77e1a\">","metadata":{}},{"cell_type":"code","source":"y = data.target\nx = data.drop([\"target\"], axis = 1)\ncolumns = x.columns.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:13:00.414576Z","iopub.execute_input":"2022-11-03T13:13:00.414986Z","iopub.status.idle":"2022-11-03T13:13:00.422259Z","shell.execute_reply.started":"2022-11-03T13:13:00.414955Z","shell.execute_reply":"2022-11-03T13:13:00.420815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = LocalOutlierFactor()\ny_pred = clf.fit_predict(x) # Returns -1 for anomalies/outliers and +1 for inliers.\nX_score = clf.negative_outlier_factor_\nX_score","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:13:02.298003Z","iopub.execute_input":"2022-11-03T13:13:02.299509Z","iopub.status.idle":"2022-11-03T13:13:02.344773Z","shell.execute_reply.started":"2022-11-03T13:13:02.299463Z","shell.execute_reply":"2022-11-03T13:13:02.343167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.scatter(x.iloc[:,0], x.iloc[:,1], color = 'k', s = 3, label = 'Data Point') # radius_mean and texture_mean as an example plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:13:05.898353Z","iopub.execute_input":"2022-11-03T13:13:05.898788Z","iopub.status.idle":"2022-11-03T13:13:06.098354Z","shell.execute_reply.started":"2022-11-03T13:13:05.898755Z","shell.execute_reply":"2022-11-03T13:13:06.097143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outlier_score = pd.DataFrame()\noutlier_score[\"score\"] = X_score\n\n# threshold for negative lof values\nthreshold = -2\nfilter_ = outlier_score[\"score\"] < threshold\noutlier_index = outlier_score[filter_].index.tolist()\n\n# Let's plot the outliers based on threshold we set\nplt.figure(figsize = (16, 9))\nplt.scatter(x.iloc[outlier_index,0], x.iloc[outlier_index,1], color = 'blue', s = 40, label = 'Outliers')\nplt.scatter(x.iloc[:,0], x.iloc[:,1], color = 'k', s = 3, label = 'Data Points')\nradius = (X_score.max() - X_score) / (X_score.max() - X_score.min())  # Normalization\nplt.scatter(x.iloc[:,0], x.iloc[:,1], s=1000*radius, edgecolors = \"r\", facecolors = \"none\", label = \"Outlier Scores\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:13:07.770052Z","iopub.execute_input":"2022-11-03T13:13:07.770510Z","iopub.status.idle":"2022-11-03T13:13:08.093709Z","shell.execute_reply.started":"2022-11-03T13:13:07.770478Z","shell.execute_reply":"2022-11-03T13:13:08.092492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop outliers\nx = x.drop(outlier_index)\ny = y.drop(outlier_index)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:13:11.293283Z","iopub.execute_input":"2022-11-03T13:13:11.293758Z","iopub.status.idle":"2022-11-03T13:13:11.305845Z","shell.execute_reply.started":"2022-11-03T13:13:11.293718Z","shell.execute_reply":"2022-11-03T13:13:11.304333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-test split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:14:41.158564Z","iopub.execute_input":"2022-11-03T13:14:41.158926Z","iopub.status.idle":"2022-11-03T13:14:41.165929Z","shell.execute_reply.started":"2022-11-03T13:14:41.158898Z","shell.execute_reply":"2022-11-03T13:14:41.164578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardization\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:14:11.702571Z","iopub.execute_input":"2022-11-03T13:14:11.703050Z","iopub.status.idle":"2022-11-03T13:14:11.715027Z","shell.execute_reply.started":"2022-11-03T13:14:11.703012Z","shell.execute_reply":"2022-11-03T13:14:11.713791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = y_train.reset_index().drop(\"index\", axis = 1)\nx_train = pd.DataFrame(x_train, columns = columns)\ntrain_df = pd.concat([x_train, y_train], axis = 1)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:14:13.705452Z","iopub.execute_input":"2022-11-03T13:14:13.705883Z","iopub.status.idle":"2022-11-03T13:14:13.743496Z","shell.execute_reply.started":"2022-11-03T13:14:13.705851Z","shell.execute_reply":"2022-11-03T13:14:13.742403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# standardized train df\ntrain_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:05.267164Z","iopub.execute_input":"2022-11-03T13:06:05.267521Z","iopub.status.idle":"2022-11-03T13:06:05.364051Z","shell.execute_reply.started":"2022-11-03T13:06:05.267490Z","shell.execute_reply":"2022-11-03T13:06:05.362867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-11-03T13:06:05.365498Z","iopub.execute_input":"2022-11-03T13:06:05.365816Z","iopub.status.idle":"2022-11-03T13:06:05.379533Z","shell.execute_reply.started":"2022-11-03T13:06:05.365788Z","shell.execute_reply":"2022-11-03T13:06:05.378275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_melted = pd.melt(train_df, id_vars = \"target\", var_name = \"feature\", value_name = \"value\")\ndata_melted.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:05.381601Z","iopub.execute_input":"2022-11-03T13:06:05.381998Z","iopub.status.idle":"2022-11-03T13:06:05.400379Z","shell.execute_reply.started":"2022-11-03T13:06:05.381966Z","shell.execute_reply":"2022-11-03T13:06:05.399262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# boxplot\nplt.figure(figsize = (18, 8))\nsns.boxplot(x = \"feature\", y = \"value\", hue = \"target\", data = data_melted)\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:05.402005Z","iopub.execute_input":"2022-11-03T13:06:05.402389Z","iopub.status.idle":"2022-11-03T13:06:06.867188Z","shell.execute_reply.started":"2022-11-03T13:06:05.402353Z","shell.execute_reply":"2022-11-03T13:06:06.866077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets visualize pairplot again with densities under a determined threshold value\nthreshold = 0.7\nfilter_ = np.abs(corr_matrix['target']) > threshold\ncorr_features = corr_matrix.columns[filter_].tolist()\nsns.pairplot(train_df[corr_features], diag_kind = 'kde', markers = \"+\", hue = 'target')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:06.868630Z","iopub.execute_input":"2022-11-03T13:06:06.868959Z","iopub.status.idle":"2022-11-03T13:06:22.179491Z","shell.execute_reply.started":"2022-11-03T13:06:06.868929Z","shell.execute_reply":"2022-11-03T13:06:22.178379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"5\"></a>\n### Model","metadata":{}},{"cell_type":"markdown","source":"<a id = \"6\"></a>\n#### K-Nearest Neighbors (KNN) Algorithm","metadata":{}},{"cell_type":"markdown","source":"K-nearest neighbors (KNN) is a type of supervised learning algorithm used for both regression and classification. KNN tries to predict the correct class for the test data by calculating the distance between the test data and all the training points. Then select the K number of points which is closet to the test data. The KNN algorithm calculates the probability of the test data belonging to the classes of ‘K’ training data and class holds the highest probability will be selected. In the case of regression, the value is the mean of the ‘K’ selected training points.\n\nLet see the below example to make it a better understanding","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/828/0*34SajbTO2C5Lvigs.png\" width=\"500\" height=\"600\">","metadata":{}},{"cell_type":"markdown","source":"Source: [https://medium.com/swlh/k-nearest-neighbor-ca2593d7a3c4]","metadata":{}},{"cell_type":"code","source":"# KNN Model with k = 2\nknn = KNeighborsClassifier(n_neighbors = 2)\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nacc = accuracy_score(y_test, y_pred)\nscore = knn.score(x_test, y_test)\nprint(\"Score: \", score)\nprint(\"Confusion matrix: \")\nprint(cm)\nprint(\"Basic KNN accuracy: \", acc)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:22.180917Z","iopub.execute_input":"2022-11-03T13:06:22.181273Z","iopub.status.idle":"2022-11-03T13:06:22.213362Z","shell.execute_reply.started":"2022-11-03T13:06:22.181239Z","shell.execute_reply":"2022-11-03T13:06:22.212059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model score is fairly good but we can do better with hyperparameter optimization.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"7\"></a>\n#### KNN Best Parameters","metadata":{}},{"cell_type":"code","source":"# Choosing best KNN parameters\ndef KNN_Best_Params(x_train, x_test, y_train, y_test):\n    \n    k_range = list(range(1,31))\n    weight_options = [\"uniform\", \"distance\"]\n    print()\n    param_grid = dict(n_neighbors = k_range, weights = weight_options)\n    \n    knn = KNeighborsClassifier()\n    grid = GridSearchCV(knn, param_grid, cv = 10, scoring = \"accuracy\")\n    grid.fit(x_train, y_train)\n    \n    print(\"Best training score {} with parameters: {}\".format(grid.best_score_, grid.best_params_))\n    print()\n    \n    knn = KNeighborsClassifier(**grid.best_params_)\n    knn.fit(x_train, y_train)\n    \n    y_pred_test = knn.predict(x_test)\n    y_pred_train = knn.predict(x_train)\n    \n    cm_test = confusion_matrix(y_test, y_pred_test)\n    cm_train = confusion_matrix(y_train, y_pred_train)\n    \n    acc_test = accuracy_score(y_test, y_pred_test)\n    acc_train = accuracy_score(y_train, y_pred_train)\n    print(\"Test score: {}, train score: {}\".format(acc_test, acc_train))\n    print()\n    print(\"CM Test\")\n    print(cm_test)\n    print(\"CM Train\")\n    print(cm_train)\n    \n    return grid\n\ngrid = KNN_Best_Params(x_train, x_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:22.215024Z","iopub.execute_input":"2022-11-03T13:06:22.216527Z","iopub.status.idle":"2022-11-03T13:06:31.245797Z","shell.execute_reply.started":"2022-11-03T13:06:22.216481Z","shell.execute_reply":"2022-11-03T13:06:31.244408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can say that this is overfitting because train accuracy is **100%** while test accuracy is **94%.** Overfitting must be solved later.","metadata":{}},{"cell_type":"markdown","source":"**Overfitting vs. Underfitting**\n\nOverfitting is a concept in data science, which occurs when a statistical model fits exactly against its training data. When this happens, the algorithm unfortunately cannot perform accurately against unseen data, defeating its purpose. Generalization of a model to new data is ultimately what allows us to use machine learning algorithms every day to make predictions and classify data.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://1.cms.s81c.com/sites/default/files/2021-03-03/model-over-fitting.png\" width=\"600\" height=\"600\">","metadata":{}},{"cell_type":"markdown","source":"Source: [https://www.ibm.com/cloud/learn/overfitting]","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://1.cms.s81c.com/sites/default/files/2021-03-03/classic%20overfitting_0.jpg\" width=\"400\" height=\"400\">","metadata":{}},{"cell_type":"markdown","source":"One of the techniques to solve overfitting is to reduce model complexity (dimensionality reduction) so we will do that to increase test accuracy and model success.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"8\"></a>\n### Dimensionality Reduction","metadata":{}},{"cell_type":"markdown","source":"<a id = \"9\"></a>\n#### Principal Component Analysis (PCA)","metadata":{}},{"cell_type":"markdown","source":"Principal component analysis, or PCA, is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.\n\nReducing the number of variables of a data set naturally comes at the expense of accuracy, but the trick in dimensionality reduction is to trade a little accuracy for simplicity. Because smaller data sets are easier to explore and visualize and make analyzing data much easier and faster for machine learning algorithms without extraneous variables to process.\n\nSo, to sum up, the idea of PCA is simple — reduce the number of variables of a data set, while preserving as much information as possible.","metadata":{}},{"cell_type":"markdown","source":"<img alt=\"Principal Component Analysis second principal\" src=\"https://builtin.com/sites/www.builtin.com/files/inline-images/national/Principal%2520Component%2520Analysis%2520second%2520principal.gif\" width=\"700\" height=\"400\">","metadata":{}},{"cell_type":"markdown","source":"Source: [https://builtin.com/data-science/step-step-explanation-principal-component-analysis]","metadata":{}},{"cell_type":"markdown","source":"**Eigen values and eigen vectors**","metadata":{}},{"cell_type":"code","source":"# Assume that we have two arrays to find eigen values and eigen vectors\nx2 = np.array([2.4, 0.6, 2.1, 2, 3, 2.5, 1.9, 1.1, 1.5, 1.2])\ny2 = np.array([2.5, 0.7, 2.9, 2.2, 3, 2.3, 2, 1.1, 1.6, 0.8])\nplt.scatter(x2,y2)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:31.248148Z","iopub.execute_input":"2022-11-03T13:06:31.249041Z","iopub.status.idle":"2022-11-03T13:06:31.454632Z","shell.execute_reply.started":"2022-11-03T13:06:31.248991Z","shell.execute_reply":"2022-11-03T13:06:31.453755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform data to (0,0) center\nx_mean = np.mean(x2)\ny_mean = np.mean(y2)\nx2 = x2 - x_mean\ny2 = y2 - y_mean\nplt.scatter(x2,y2)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:31.456098Z","iopub.execute_input":"2022-11-03T13:06:31.456446Z","iopub.status.idle":"2022-11-03T13:06:31.668603Z","shell.execute_reply.started":"2022-11-03T13:06:31.456417Z","shell.execute_reply":"2022-11-03T13:06:31.667742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cov matrix\ncov = np.cov(x2, y2)\ncov","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:31.669825Z","iopub.execute_input":"2022-11-03T13:06:31.670403Z","iopub.status.idle":"2022-11-03T13:06:31.677448Z","shell.execute_reply.started":"2022-11-03T13:06:31.670369Z","shell.execute_reply":"2022-11-03T13:06:31.676336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finding eigen values and eigen vectors","metadata":{}},{"cell_type":"code","source":"from numpy import linalg as LA\nw, v = LA.eig(cov)\nw","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:31.678781Z","iopub.execute_input":"2022-11-03T13:06:31.679137Z","iopub.status.idle":"2022-11-03T13:06:31.691966Z","shell.execute_reply.started":"2022-11-03T13:06:31.679109Z","shell.execute_reply":"2022-11-03T13:06:31.690892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:31.697704Z","iopub.execute_input":"2022-11-03T13:06:31.698066Z","iopub.status.idle":"2022-11-03T13:06:31.705287Z","shell.execute_reply.started":"2022-11-03T13:06:31.698035Z","shell.execute_reply":"2022-11-03T13:06:31.704137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, what do all these mean?","metadata":{}},{"cell_type":"markdown","source":"w(…, M) array\nThe eigenvalues, each repeated according to its multiplicity. The eigenvalues are not necessarily ordered. The resulting array will be of complex type, unless the imaginary part is zero in which case it will be cast to a real type. When a is real the resulting eigenvalues will be real (0 imaginary part) or occur in conjugate pairs\n\nv(…, M, M) array\nThe normalized (unit “length”) eigenvectors, such that the column v[:,i] is the eigenvector corresponding to the eigenvalue w[i].","metadata":{}},{"cell_type":"code","source":"p1 = v[:, 1]\np2 = v[:, 0]","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:31.707100Z","iopub.execute_input":"2022-11-03T13:06:31.707422Z","iopub.status.idle":"2022-11-03T13:06:31.715517Z","shell.execute_reply.started":"2022-11-03T13:06:31.707394Z","shell.execute_reply":"2022-11-03T13:06:31.714467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p1","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:31.716709Z","iopub.execute_input":"2022-11-03T13:06:31.717567Z","iopub.status.idle":"2022-11-03T13:06:31.729051Z","shell.execute_reply.started":"2022-11-03T13:06:31.717534Z","shell.execute_reply":"2022-11-03T13:06:31.727976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing eigen vectors and eigen values\nplt.scatter(x2,y2)\n# main component\nplt.plot([-2 * p1[0], 2 * p1[0]] , [-2 * p1[1], 2 * p1[1]])\n# small component\nplt.plot([-1 * p2[0], 1 * p2[0]] , [-1 * p2[1], 1 * p2[1]])","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:06:31.730730Z","iopub.execute_input":"2022-11-03T13:06:31.731053Z","iopub.status.idle":"2022-11-03T13:06:31.956878Z","shell.execute_reply.started":"2022-11-03T13:06:31.731023Z","shell.execute_reply":"2022-11-03T13:06:31.955786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## PCA\nscaler = StandardScaler()\nx_scaled = scaler.fit_transform(x)\n\npca = PCA(n_components = 2) # reduction to 2 features\npca.fit(x_scaled)\nx_reduced_pca = pca.transform(x_scaled)\npca_data = pd.DataFrame(x_reduced_pca, columns = [\"p1\",\"p2\"])\npca_data[\"target\"] = y.reset_index().drop(\"index\", axis = 1)\n\n# visualize PCA\nplt.figure(figsize = (10, 6))\nsns.scatterplot(x = \"p1\", y = \"p2\", hue = \"target\", data = pca_data)\nplt.title(\"PCA: p1 vs p2\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:19:07.806983Z","iopub.execute_input":"2022-11-03T13:19:07.807479Z","iopub.status.idle":"2022-11-03T13:19:08.191951Z","shell.execute_reply.started":"2022-11-03T13:19:07.807441Z","shell.execute_reply":"2022-11-03T13:19:08.190842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-test split\nx_train_pca, x_test_pca, y_train_pca, y_test_pca = train_test_split(x_reduced_pca, y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T13:53:47.093605Z","iopub.status.idle":"2022-11-03T13:53:47.094337Z","shell.execute_reply.started":"2022-11-03T13:53:47.094082Z","shell.execute_reply":"2022-11-03T13:53:47.094109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_pca = KNN_Best_Params(x_train_pca, x_test_pca, y_train_pca, y_test_pca)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T14:08:22.743865Z","iopub.execute_input":"2022-11-03T14:08:22.744344Z","iopub.status.idle":"2022-11-03T14:08:24.646945Z","shell.execute_reply.started":"2022-11-03T14:08:22.744310Z","shell.execute_reply":"2022-11-03T14:08:24.645178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize PCA\ncmap_light = ListedColormap([\"orange\", \"cornflowerblue\"])\ncmap_bold = ListedColormap([\"darkorange\", \"darkblue\"])\n\nh = .05\nX = x_reduced_pca\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 0].min() - 1, X[:, 0].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\nZ = grid_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap = cmap_light)\n\n# plot also the trainin points\nplt.scatter(X[:,0], X[:,1], c = y, cmap = cmap_bold, edgecolor = \"k\", s = 20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classification (k = %i, weights = '%s')\" % (len(np.unique(y)), grid_pca.best_estimator_.n_neighbors, grid_pca.best_estimator_.weights))","metadata":{"execution":{"iopub.status.busy":"2022-11-03T14:21:57.963754Z","iopub.execute_input":"2022-11-03T14:21:57.964370Z","iopub.status.idle":"2022-11-03T14:22:03.480440Z","shell.execute_reply.started":"2022-11-03T14:21:57.964306Z","shell.execute_reply":"2022-11-03T14:22:03.479294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Which points did we make a wrong classification on test data using PCA?","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(**grid_pca.best_params_)\nknn.fit(x_train_pca, y_train_pca)\ny_pred_pca = knn.predict(x_test_pca)\nacc_test_pca = accuracy_score(y_pred_pca, y_test_pca)\nknn.score(x_test_pca, y_test_pca)\n\ntest_data = pd.DataFrame()\ntest_data[\"X_test_pca_p1\"] = x_test_pca[:,0]\ntest_data[\"X_test_pca_p2\"] = x_test_pca[:,1]\ntest_data[\"Y_pred_pca\"] = y_pred_pca\ntest_data[\"Y_test_pca\"] = y_test_pca.reset_index().drop(\"index\", axis = 1)\n\nplt.figure(figsize = (14, 8))\nsns.scatterplot(x = \"X_test_pca_p1\", y = \"X_test_pca_p2\", hue=\"Y_test_pca\", data = test_data)\n\ndiff = np.where(y_pred_pca != y_test_pca)[0]\nplt.scatter(test_data.iloc[diff, 0], test_data.iloc[diff, 1], label = \"Wrong Classified\", alpha = 0.2, color = \"red\",s = 1000)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T14:25:01.305202Z","iopub.execute_input":"2022-11-03T14:25:01.305686Z","iopub.status.idle":"2022-11-03T14:25:01.656246Z","shell.execute_reply.started":"2022-11-03T14:25:01.305652Z","shell.execute_reply":"2022-11-03T14:25:01.654836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"10\"></a>\n#### Neighborhood Component Analysis (NCA)","metadata":{}},{"cell_type":"markdown","source":"Neighbourhood components analysis is a supervised learning method for classifying multivariate data into distinct classes according to a given distance metric over the data. Functionally, it serves the same purposes as the K-nearest neighbors algorithm, and makes direct use of a related concept termed stochastic nearest neighbours.\n\nRather than having the user specify some arbitrary distance metric, NCA learns it by choosing a parameterized family of quadratic distance metrics, constructing a loss function of the parameters, and optimizing it with gradient descent. Furthermore, the learned distance metric can explicitly be made low-dimensional, solving test-time storage and search issues. How does NCA do this?\n\nThe goal of the learning algorithm then, is to optimize the performance of kNN on future test data. Since we don’t a priori know the test data, we can choose instead to optimize the closest thing in our toolbox: the leave-one-out (LOO) performance of the training data.","metadata":{}},{"cell_type":"markdown","source":"<img alt=\"Principal Component Analysis second principal\" src=\"https://d3i71xaburhd42.cloudfront.net/24c287d97982216c8f35c8d326dc2ec2d2475f3e/6-Figure2-1.png\" width=\"500\" height=\"300\">","metadata":{}},{"cell_type":"code","source":"# NCA\nnca = NeighborhoodComponentsAnalysis(n_components = 2, random_state = 42)\nnca.fit(x_scaled, y)\nx_reduced_nca = nca.transform(x_scaled)\nnca_data = pd.DataFrame(x_reduced_nca, columns = [\"p1\",\"p2\"])\nnca_data[\"target\"] = y.reset_index().drop(\"index\", axis = 1)\n\nplt.figure(figsize = (10, 6))\nsns.scatterplot(x = \"p1\", y = \"p2\", hue = \"target\", data = nca_data)\nplt.title(\"NCA: p1 vs p2\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T14:00:57.666599Z","iopub.execute_input":"2022-11-03T14:00:57.667342Z","iopub.status.idle":"2022-11-03T14:00:59.013958Z","shell.execute_reply.started":"2022-11-03T14:00:57.667296Z","shell.execute_reply":"2022-11-03T14:00:59.012515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-test split\nx_train_nca, x_test_nca, y_train_nca, y_test_nca = train_test_split(x_reduced_nca, y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T14:00:59.015772Z","iopub.execute_input":"2022-11-03T14:00:59.016131Z","iopub.status.idle":"2022-11-03T14:00:59.023436Z","shell.execute_reply.started":"2022-11-03T14:00:59.016098Z","shell.execute_reply":"2022-11-03T14:00:59.022191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_nca = KNN_Best_Params(x_train_nca, x_test_nca, y_train_nca, y_test_nca)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T14:00:59.081445Z","iopub.execute_input":"2022-11-03T14:00:59.081861Z","iopub.status.idle":"2022-11-03T14:01:01.001703Z","shell.execute_reply.started":"2022-11-03T14:00:59.081828Z","shell.execute_reply":"2022-11-03T14:01:01.000486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize NCA\ncmap_light = ListedColormap([\"orange\", \"cornflowerblue\"])\ncmap_bold = ListedColormap([\"darkorange\", \"darkblue\"])\n\nh = .2\nX = x_reduced_nca\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 0].min() - 1, X[:, 0].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\nZ = grid_nca.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap = cmap_light)\n\n# plot also the trainin points\nplt.scatter(X[:,0], X[:,1], c = y, cmap = cmap_bold, edgecolor = \"k\", s = 20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classification (k = %i, weights = '%s')\" % (len(np.unique(y)), grid_nca.best_estimator_.n_neighbors, grid_nca.best_estimator_.weights))","metadata":{"execution":{"iopub.status.busy":"2022-11-03T14:22:03.482615Z","iopub.execute_input":"2022-11-03T14:22:03.483826Z","iopub.status.idle":"2022-11-03T14:22:10.154976Z","shell.execute_reply.started":"2022-11-03T14:22:03.483773Z","shell.execute_reply":"2022-11-03T14:22:10.153586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, which points did we make a wrong classification on test data using NCA?","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(**grid_nca.best_params_)\nknn.fit(x_train_nca, y_train_nca)\ny_pred_nca = knn.predict(x_test_nca)\nacc_test_nca = accuracy_score(y_pred_nca, y_test_nca)\nknn.score(x_test_nca, y_test_nca)\n\ntest_data = pd.DataFrame()\ntest_data[\"X_test_nca_p1\"] = x_test_nca[:,0]\ntest_data[\"X_test_nca_p2\"] = x_test_nca[:,1]\ntest_data[\"Y_pred_nca\"] = y_pred_nca\ntest_data[\"Y_test_nca\"] = y_test_nca.reset_index().drop(\"index\", axis = 1)\n\nplt.figure(figsize = (14, 8))\nsns.scatterplot(x = \"X_test_nca_p1\", y = \"X_test_nca_p2\", hue=\"Y_test_nca\", data = test_data)\n\ndiff = np.where(y_pred_nca != y_test_nca)[0]\nplt.scatter(test_data.iloc[diff, 0], test_data.iloc[diff, 1], label = \"Wrong Classified\", alpha = 0.2, color = \"red\",s = 1000)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T14:24:24.875564Z","iopub.execute_input":"2022-11-03T14:24:24.876009Z","iopub.status.idle":"2022-11-03T14:24:25.208226Z","shell.execute_reply.started":"2022-11-03T14:24:24.875975Z","shell.execute_reply":"2022-11-03T14:24:25.206560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Thanks for looking at this kernel. If you like it don't forget to upvote!**","metadata":{}}]}